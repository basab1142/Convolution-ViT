{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:06:50.567289Z","iopub.status.busy":"2024-02-25T10:06:50.566901Z","iopub.status.idle":"2024-02-25T10:07:01.296355Z","shell.execute_reply":"2024-02-25T10:07:01.295468Z","shell.execute_reply.started":"2024-02-25T10:06:50.567257Z"},"id":"2_UKjWcdGaC9","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"execution":{"iopub.execute_input":"2024-02-25T10:07:21.278254Z","iopub.status.busy":"2024-02-25T10:07:21.277732Z","iopub.status.idle":"2024-02-25T10:07:21.336820Z","shell.execute_reply":"2024-02-25T10:07:21.335763Z","shell.execute_reply.started":"2024-02-25T10:07:21.278222Z"},"id":"cFust9HEWLgE","outputId":"0749321c-9e79-485a-9714-9f5fc326199b","trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:07:23.301061Z","iopub.status.busy":"2024-02-25T10:07:23.300349Z","iopub.status.idle":"2024-02-25T10:07:23.318768Z","shell.execute_reply":"2024-02-25T10:07:23.317757Z","shell.execute_reply.started":"2024-02-25T10:07:23.301026Z"},"id":"6-w4u4ARoPO0","trusted":true},"outputs":[],"source":["class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, n_embd,head_size):\n","        super().__init__()\n","        self.key = nn.Linear(n_embd, head_size, bias=False)\n","        self.query = nn.Linear(n_embd, head_size, bias=False)\n","        self.value = nn.Linear(n_embd, head_size, bias=False)\n","\n","        self.dropout = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        k = self.key(x)   # (B,T,C)\n","        q = self.query(x) # (B,T,C)\n","        # compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T)\n","        wei = self.dropout(wei)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) # (B,T,C)\n","        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size, n_embd):\n","        super().__init__()\n","        self.n_embd = n_embd\n","        self.heads = nn.ModuleList([Head(n_embd, head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(self.n_embd, self.n_embd)\n","        self.dropout = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        out = self.dropout(self.proj(out))\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd),\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd),\n","            nn.Dropout(0.2),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Block(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self, n_embd, n_head):\n","        # n_embd: embedding dimension, n_head: the number of heads we'd like\n","        super().__init__()\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size, n_embd)\n","        self.ffwd = FeedFoward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"_OyIhAz8X_rf"},"source":["### Pathcify the image"]},{"cell_type":"markdown","metadata":{"id":"t_nE6oMhaTAR"},"source":["Image after pathify = (N, PxP, HxC/P x WxC/P) -> (N, #Patches, Patch dimensionality)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:07:27.230882Z","iopub.status.busy":"2024-02-25T10:07:27.229956Z","iopub.status.idle":"2024-02-25T10:07:27.260575Z","shell.execute_reply":"2024-02-25T10:07:27.259714Z","shell.execute_reply.started":"2024-02-25T10:07:27.230846Z"},"id":"ecdixTFXbsBZ","trusted":true},"outputs":[],"source":["x = torch.rand(3,1, 28, 28)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:07:29.183157Z","iopub.status.busy":"2024-02-25T10:07:29.182546Z","iopub.status.idle":"2024-02-25T10:07:29.189229Z","shell.execute_reply":"2024-02-25T10:07:29.188162Z","shell.execute_reply.started":"2024-02-25T10:07:29.183126Z"},"id":"Vlm8QTDRahlw","trusted":true},"outputs":[],"source":["class Patchify(nn.Module):\n","    def __init__(self, patch_size=4):\n","        super().__init__()\n","        self.p = patch_size\n","        self.unfold = torch.nn.Unfold(kernel_size=patch_size, stride=patch_size)\n","\n","    def forward(self, x):\n","\n","        bs, c, h, w = x.shape\n","\n","        x = self.unfold(x).permute(0, 2, 1)\n","\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"eKX2i4gEeCv6"},"source":["## MAIN FUNCTION"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:07:31.263238Z","iopub.status.busy":"2024-02-25T10:07:31.262072Z","iopub.status.idle":"2024-02-25T10:07:31.278096Z","shell.execute_reply":"2024-02-25T10:07:31.277306Z","shell.execute_reply.started":"2024-02-25T10:07:31.263193Z"},"id":"vb0JpBLWeEiD","trusted":true},"outputs":[],"source":["class ViT(nn.Module):\n","\n","  def __init__(self, input_shape = (1, 28, 28), patch_size = 4, actual_image_shape = (1, 32, 32), output_dim = 10):\n","    super(ViT, self).__init__()\n","    self.input_shape = input_shape\n","    self.patch_size =  (patch_size, patch_size)\n","    self.output_dim = output_dim\n","    self.hidden = 8\n","    self.n_heads = 2\n","    self.n_blocks = 4\n","    self.num_patches = int(input_shape[1] // patch_size)\n","\n","    self.convBlock = nn.Sequential(\n","        nn.Conv2d(in_channels= 1, out_channels= 10, kernel_size = 3),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels= 10, out_channels= 10, kernel_size = 3)\n","    )\n","    self.convBlock2 = nn.Sequential(\n","        nn.Conv2d(in_channels= 1, out_channels= 10, kernel_size = 3),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels= 10, out_channels= 10, kernel_size = 3)\n","    )\n","    self.Patch = Patchify()\n","    # linear mapping from pathes of 4x4 to 8 dim vectors\n","    self.input_dim = input_shape[0]*(patch_size**2)*10\n","    self.mapping = nn.Linear(self.input_dim, self.hidden)\n","    # special token for classification\n","    self.class_token = nn.Parameter(torch.rand(1, self.hidden))\n","    # postiona embedding table\n","    self.position_embedding_table = nn.Embedding(self.num_patches**2 + 1, self.hidden)\n","    # Multihead Attention block\n","    self.blocks = nn.ModuleList([Block(self.hidden, self.n_heads) for _ in range(self.n_blocks)])\n","    # output layer construction\n","    self.outputLayer = nn.Sequential(\n","        nn.Linear(self.hidden, self.hidden),\n","        nn.ReLU(),\n","        #nn.BatchNorm1d(self.hidden),\n","        nn.Linear(self.hidden, output_dim),\n","        nn.Softmax(dim=-1)\n","    )\n","\n","\n","  def forward(self, x):\n","    # convolute the image first\n","    x = self.convBlock(x) + self.convBlock2(x)\n","    # Patchify\n","    x = self.Patch(x)\n","    # linear mapping from 16 -> 8\n","    x = self.mapping(x)\n","    # add special token\n","    tokens = torch.stack([torch.vstack((self.class_token, x[i])) for i in range(len(x))])\n","    # add positional embedding\n","   # print(tokens.shape[-2])\n","    positional_emb = self.position_embedding_table(torch.arange(tokens.shape[-2]).to(device))\n","    out = tokens + positional_emb\n","    # passing through Multihead self attention block\n","    for block in self.blocks:\n","            out = block(out)\n","   \n","    # now passing through MLP layer for final prediction\n","    out =  self.outputLayer(out[:, 0])\n","    return out"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:07:35.826556Z","iopub.status.busy":"2024-02-25T10:07:35.825642Z","iopub.status.idle":"2024-02-25T10:07:36.083818Z","shell.execute_reply":"2024-02-25T10:07:36.082948Z","shell.execute_reply.started":"2024-02-25T10:07:35.826522Z"},"id":"sgrkZnwbgjVS","trusted":true},"outputs":[],"source":["\n","m = ViT().to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:07:36.932421Z","iopub.status.busy":"2024-02-25T10:07:36.931807Z","iopub.status.idle":"2024-02-25T10:07:36.936689Z","shell.execute_reply":"2024-02-25T10:07:36.935872Z","shell.execute_reply.started":"2024-02-25T10:07:36.932389Z"},"id":"gT8qE-8t5eWb","trusted":true},"outputs":[],"source":["x = torch.rand(1, 1, 32, 32).to(device)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-02-25T10:07:40.845432Z","iopub.status.busy":"2024-02-25T10:07:40.844591Z","iopub.status.idle":"2024-02-25T10:07:42.651506Z","shell.execute_reply":"2024-02-25T10:07:42.650387Z","shell.execute_reply.started":"2024-02-25T10:07:40.845398Z"},"id":"nFtuVX3Cgo1H","outputId":"25a18bd9-8ac9-417f-b9cc-0c376ef04c20","trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1, 10])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["m(x).shape"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:07:45.451210Z","iopub.status.busy":"2024-02-25T10:07:45.450496Z","iopub.status.idle":"2024-02-25T10:07:45.458183Z","shell.execute_reply":"2024-02-25T10:07:45.457102Z","shell.execute_reply.started":"2024-02-25T10:07:45.451168Z"},"id":"7RnWA0KUkQqW","trusted":true},"outputs":[],"source":["block = Block(n_embd=8,n_head=2)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-02-25T10:07:45.688265Z","iopub.status.busy":"2024-02-25T10:07:45.687009Z","iopub.status.idle":"2024-02-25T10:07:45.877361Z","shell.execute_reply":"2024-02-25T10:07:45.876382Z","shell.execute_reply.started":"2024-02-25T10:07:45.688225Z"},"id":"xdECzhWBkQnb","outputId":"65c7038b-86fd-47c7-e38d-7ddb2c6883eb","trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([3, 50, 8])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["block(torch.rand(3, 50, 8)).shape"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:07:50.280903Z","iopub.status.busy":"2024-02-25T10:07:50.279737Z","iopub.status.idle":"2024-02-25T10:08:32.575134Z","shell.execute_reply":"2024-02-25T10:08:32.574178Z","shell.execute_reply.started":"2024-02-25T10:07:50.280865Z"},"id":"LSRrQ8zFkQkQ","trusted":true},"outputs":[],"source":["from pathlib import Path\n","train_dir = '/kaggle/input/dataset-lfw/lfw-deepfunneled/lfw-deepfunneled'\n","\n","data_transform = transforms.Compose([\n","    transforms.Grayscale(),\n","    transforms.Resize(size=(32, 32)),\n","    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n","    transforms.ToTensor()\n","])\n","\n","from torchvision import datasets\n","train_data = datasets.ImageFolder(root=train_dir,\n","                                  transform=data_transform,\n","                                  target_transform=None)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:09:01.522526Z","iopub.status.busy":"2024-02-25T10:09:01.522183Z","iopub.status.idle":"2024-02-25T10:09:01.526991Z","shell.execute_reply":"2024-02-25T10:09:01.526017Z","shell.execute_reply.started":"2024-02-25T10:09:01.522500Z"},"id":"OfxoBYYR6Jmw","trusted":true},"outputs":[],"source":["num_classes = len(train_data.classes)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"execution":{"iopub.execute_input":"2024-02-25T10:09:06.636196Z","iopub.status.busy":"2024-02-25T10:09:06.635353Z","iopub.status.idle":"2024-02-25T10:09:06.641746Z","shell.execute_reply":"2024-02-25T10:09:06.640738Z","shell.execute_reply.started":"2024-02-25T10:09:06.636152Z"},"id":"5Gqi8y9XUy__","outputId":"6b67c1ae-125e-4463-ab41-b6c4fc42900b","trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:09:07.345734Z","iopub.status.busy":"2024-02-25T10:09:07.344917Z","iopub.status.idle":"2024-02-25T10:09:07.350287Z","shell.execute_reply":"2024-02-25T10:09:07.349236Z","shell.execute_reply.started":"2024-02-25T10:09:07.345705Z"},"id":"-LipO3fQ30qk","trusted":true},"outputs":[],"source":["train_dataloader = DataLoader(dataset=train_data,\n","                              batch_size=1,\n","                              num_workers=1,\n","                              shuffle=True)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-02-25T10:09:07.792549Z","iopub.status.busy":"2024-02-25T10:09:07.792202Z","iopub.status.idle":"2024-02-25T10:09:07.904856Z","shell.execute_reply":"2024-02-25T10:09:07.903692Z","shell.execute_reply.started":"2024-02-25T10:09:07.792524Z"},"id":"JF4tFNZh7afD","outputId":"4850ed8a-8f49-4c48-9c37-554315e4cb93","trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1, 1, 32, 32])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(train_dataloader))[0].shape"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:09:09.744272Z","iopub.status.busy":"2024-02-25T10:09:09.743671Z","iopub.status.idle":"2024-02-25T10:09:09.753732Z","shell.execute_reply":"2024-02-25T10:09:09.752679Z","shell.execute_reply.started":"2024-02-25T10:09:09.744232Z"},"id":"ZX0s3sRf3_eo","trusted":true},"outputs":[],"source":["def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer):\n","    # Put model in train mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0\n","\n","    # Loop through data loader data batches\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Send data to target device\n","        X, y = X.to(device), y.to(device)\n","\n","        # 1. Forward pass\n","        y_pred = model(X)\n","\n","        # 2. Calculate  and accumulate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item()\n","\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # 4. Loss backward\n","        loss.backward()\n","\n","        # 5. Optimizer step\n","        optimizer.step()\n","\n","        # Calculate and accumulate accuracy metric across all batches\n","        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","    train_loss = train_loss / len(dataloader)\n","    train_acc = train_acc / len(dataloader)\n","    return train_loss, train_acc"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:09:10.297242Z","iopub.status.busy":"2024-02-25T10:09:10.296227Z","iopub.status.idle":"2024-02-25T10:09:10.306260Z","shell.execute_reply":"2024-02-25T10:09:10.305237Z","shell.execute_reply.started":"2024-02-25T10:09:10.297195Z"},"id":"3g8LhozY4G5x","trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm\n","\n","# 1. Take in various parameters required for training and test steps\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n","          epochs: int = 5, PATH = '/kaggle/working/LFW_ViT.pth'):\n","\n","    # 2. Create empty results dictionary\n","    results = {\"train_loss\": [],\n","        \"train_acc\": []\n","    }\n","\n","    # 3. Loop through training and testing steps for a number of epochs\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model=model,\n","                                           dataloader=train_dataloader,\n","                                           loss_fn=loss_fn,\n","                                           optimizer=optimizer)\n","\n","        print(\n","            f\"Epoch: {epoch+1} | \"\n","            f\"train_loss: {train_loss:.4f} | \"\n","            f\"train_acc: {train_acc:.4f} | \"\n","\n","        )\n","\n","        # 5. Update results dictionary\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","\n","\n","    # 6. Return the filled results at the end of the epochs\n","    torch.save(model.state_dict(), PATH)\n","    return results"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:09:11.098945Z","iopub.status.busy":"2024-02-25T10:09:11.098337Z","iopub.status.idle":"2024-02-25T10:09:11.103276Z","shell.execute_reply":"2024-02-25T10:09:11.102376Z","shell.execute_reply.started":"2024-02-25T10:09:11.098913Z"},"id":"Fhp0Iytk4uX0","trusted":true},"outputs":[],"source":["PATH = '/kaggle/working/LFW_ViT.pth'"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:09:21.830675Z","iopub.status.busy":"2024-02-25T10:09:21.829766Z","iopub.status.idle":"2024-02-25T10:09:21.855412Z","shell.execute_reply":"2024-02-25T10:09:21.854361Z","shell.execute_reply.started":"2024-02-25T10:09:21.830631Z"},"id":"TGKYPNNH4fdM","trusted":true},"outputs":[],"source":["LEARNING_RATE = 3.5e-3\n","model = ViT(output_dim = num_classes).to(device)\n","model.load_state_dict(torch.load(PATH))\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(params = model.parameters(), lr = LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-25T10:24:12.686834Z","iopub.status.busy":"2024-02-25T10:24:12.686134Z"},"id":"pZYgtKiv4gG8","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aebc89c0645d4027ac2d19b70844a554","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | train_loss: 8.6568 | train_acc: 0.0002 | \n","Epoch: 2 | train_loss: 8.6568 | train_acc: 0.0002 | \n","Epoch: 3 | train_loss: 8.6567 | train_acc: 0.0002 | \n","Epoch: 4 | train_loss: 8.6567 | train_acc: 0.0002 | \n","Epoch: 5 | train_loss: 8.6566 | train_acc: 0.0002 | \n","Epoch: 6 | train_loss: 8.6565 | train_acc: 0.0002 | \n","Epoch: 7 | train_loss: 8.6563 | train_acc: 0.0002 | \n","Epoch: 8 | train_loss: 8.6561 | train_acc: 0.0003 | \n","Epoch: 9 | train_loss: 8.6555 | train_acc: 0.0007 | \n","Epoch: 10 | train_loss: 8.6538 | train_acc: 0.0208 | \n","Epoch: 11 | train_loss: 8.6477 | train_acc: 0.0401 | \n","Epoch: 12 | train_loss: 8.6336 | train_acc: 0.0401 | \n","Epoch: 13 | train_loss: 8.6220 | train_acc: 0.0401 | \n","Epoch: 14 | train_loss: 8.6181 | train_acc: 0.0401 | \n"]}],"source":["NUM_EPOCHS = 20\n","Results = train(model=model,\n","                train_dataloader=train_dataloader,\n","                optimizer=optimizer,\n","                loss_fn=loss_fn,\n","                epochs=NUM_EPOCHS)"]},{"cell_type":"code","execution_count":128,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6khAgoiplzD0","outputId":"331a1989-a1eb-48a4-a1b0-3df37d10fe4b"},"outputs":[{"data":{"text/plain":["{'train_loss': [8.656781060097664], 'train_acc': [0.00015113730824454016]}"]},"execution_count":128,"metadata":{},"output_type":"execute_result"}],"source":["Results"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4492557,"sourceId":7697095,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
